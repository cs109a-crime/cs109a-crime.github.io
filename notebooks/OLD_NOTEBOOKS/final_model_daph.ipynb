{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Random Forest Model\n",
    "\n",
    "This is the code that takes in our fully cleaned and feature engineered dataset, trains a model on 80% of the data, and tests it on the other 20% to check accuracy. This gives us an understanding of how much faith we can have in our model. Were it to be used in a real life scenario, we would train it on all available training data, and use it to predict our unknown new data points.\n",
    "\n",
    "__Import Libraries__ first order of business is to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of numpy depreciation warnings\n",
    "def warn(*args, **kwargs): pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# import python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import data science libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import and Inspect__ the dataset, which has been cleaned, prepared, and feature engineered in the file `feature_engineering.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>closest_property_value</th>\n",
       "      <th>neighborhood_avg</th>\n",
       "      <th>lamp_min_dist</th>\n",
       "      <th>...</th>\n",
       "      <th>hospital_min_dist</th>\n",
       "      <th>school_min_dist</th>\n",
       "      <th>school_density</th>\n",
       "      <th>DAY_OF_WEEK_Friday</th>\n",
       "      <th>DAY_OF_WEEK_Monday</th>\n",
       "      <th>DAY_OF_WEEK_Saturday</th>\n",
       "      <th>DAY_OF_WEEK_Sunday</th>\n",
       "      <th>DAY_OF_WEEK_Thursday</th>\n",
       "      <th>DAY_OF_WEEK_Tuesday</th>\n",
       "      <th>DAY_OF_WEEK_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.364331</td>\n",
       "      <td>-71.063193</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.843299</td>\n",
       "      <td>14.987931</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.314630</td>\n",
       "      <td>-71.092615</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.754483</td>\n",
       "      <td>13.036407</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.279675</td>\n",
       "      <td>-71.083813</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.997027</td>\n",
       "      <td>13.034991</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.379124</td>\n",
       "      <td>-71.028082</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.638769</td>\n",
       "      <td>15.682548</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.379124</td>\n",
       "      <td>-71.028082</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.774790</td>\n",
       "      <td>13.015478</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lat       Long  MONTH  HOUR  TAVG  PRCP  SNOW  \\\n",
       "0  42.364331 -71.063193      9     4  70.0   0.0   0.0   \n",
       "1  42.314630 -71.092615      9     4  70.0   0.0   0.0   \n",
       "2  42.279675 -71.083813      9     3  70.0   0.0   0.0   \n",
       "3  42.379124 -71.028082      9     2  70.0   0.0   0.0   \n",
       "4  42.379124 -71.028082      9     2  70.0   0.0   0.0   \n",
       "\n",
       "   closest_property_value  neighborhood_avg  lamp_min_dist  \\\n",
       "0               16.843299         14.987931       0.000070   \n",
       "1               12.754483         13.036407       0.000083   \n",
       "2               12.997027         13.034991       0.000078   \n",
       "3               15.638769         15.682548       0.000109   \n",
       "4               12.774790         13.015478       0.000157   \n",
       "\n",
       "           ...            hospital_min_dist school_min_dist  school_density  \\\n",
       "0          ...                     0.001813        0.008471             2.0   \n",
       "1          ...                     0.003940        0.001727             8.0   \n",
       "2          ...                     0.008593        0.003386             5.0   \n",
       "3          ...                     0.038462        0.002467             4.0   \n",
       "4          ...                     0.038462        0.002467             4.0   \n",
       "\n",
       "   DAY_OF_WEEK_Friday  DAY_OF_WEEK_Monday  DAY_OF_WEEK_Saturday  \\\n",
       "0                   0                   0                     0   \n",
       "1                   0                   0                     0   \n",
       "2                   0                   0                     0   \n",
       "3                   0                   0                     0   \n",
       "4                   0                   0                     0   \n",
       "\n",
       "   DAY_OF_WEEK_Sunday  DAY_OF_WEEK_Thursday  DAY_OF_WEEK_Tuesday  \\\n",
       "0                   1                     0                    0   \n",
       "1                   1                     0                    0   \n",
       "2                   1                     0                    0   \n",
       "3                   1                     0                    0   \n",
       "4                   1                     0                    0   \n",
       "\n",
       "   DAY_OF_WEEK_Wednesday  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df = pd.read_csv('data/master_df.csv')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split the Dataset__ into predictor variables (X) and response (y) variables. Then, further split each into a training set and a test set, stratifying on the category (y) to ensure that we get an accurate measurement of how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into predictors and response variables\n",
    "X = master_df.drop(['category'], axis=1) \n",
    "y = master_df['category']\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A Note About the Baseline Model:__ to have something to compare to, we looked at what sort of accuracy we would want our model to beat. One way to think of it is the accuracy we would get if responders guessed categories at random (this would be the accuracy given no information about the past). Another way to think about it is the accuracy that a model would produce if it just guessed the most common category 100% of the time (a very naive model). We included both, and decided to compare our model to the latter, because it is more realistic that we do have information about the past when making these decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive baseline: 20.0 %\n",
      "model baseline: 35.9 %\n"
     ]
    }
   ],
   "source": [
    "# calculate baseline accuracy if we guessed categories at random\n",
    "naive_baseline = 1 / len(master_df.category.value_counts())\n",
    "\n",
    "# calculate baseline accuracy if the model assumed the most common category\n",
    "model_baseline   = master_df.category.value_counts()[0] / sum(master_df.category.value_counts())\n",
    "\n",
    "print('naive baseline:', 100*naive_baseline, '%')\n",
    "print('model baseline:', round(100*model_baseline,1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set Up the Model__ using the knowledge we gained from refining different models, all of which can be found in the folder `old_models`. From this refining, we decided that the best model would be a Random Forest with a maximum tree depth of 10 (so as to get the best test accuracy without overfitting too much to the training set). We tested each of the hyper parameters that `RandomForestClassifier` takes, but none helped us improve our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rf(best_depth):\n",
    "\n",
    "    # set up the model and fit on training data\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=best_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict train and test data to check accuracy\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # evaluate performance using accuracy score\n",
    "    acc_random_forest_training = accuracy_score(y_train, y_pred_train)*100\n",
    "    acc_random_forest_testing = accuracy_score(y_test, y_pred_test)*100\n",
    "\n",
    "    print(\"Random Forest Accuracy, Training Set : {:0.2f}%\".format(acc_random_forest_training))\n",
    "    print(\"Random Forest Accuracy, Testing Set :  {:0.2f}%\".format(acc_random_forest_testing))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train and Evaluate__ the model using the train and test sets. We chose to evaluate our model based on accuracy because other methods didn't make sense. For example, we do care a lot about the false negatives, since not all our categories have the same number of entries, however, since this is not a binary outcome problem, it didn't make sense to use ROC scores. After careful inspection of the class predictions and the `predict_proba` results, we decided that the accuracy was a good measure of how well our model was performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy, Training Set : 50.74%\n",
      "Random Forest Accuracy, Testing Set :  46.08%\n"
     ]
    }
   ],
   "source": [
    "model = test_rf(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Analysis:__ as we can see above, our trained model (~50%) performed better than the baseline model (35%). Although the model itself seems simple (we just trained a simple random forest on our training data), it is in fact the result of many careful decisions. The real model refining happened in the feature engineering and feature selection process. \n",
    "\n",
    "Due to the nature of the data (crimes are hard to predict, it can hard to differentiate between a crime that involves drugs or not, and the predicors that we chose cannot possibly capture all the variability in the data), we are confident that our model's accuracy could not significantly improve without drastic changes in the data inputs.\n",
    "\n",
    "That being said, we wanted to create somethiing that could be useful for a real-life situation, i.e. how can we use the model we created to help emergency responders? The accuracy is pretty low, meaning that given an emergency, the model would only be right about what sort of response was needed 50% of the time. So we decided to use our model to help narrow down the types of responses that could be needed to 2 instead of 5. We could use our model to tell responders \"this emergency likely involves drugs and weapons posessions\", or \"this emergency likely involves domestic issues and drugs\". This could help responders send different specialists to each situation, making their response more effective.\n",
    "\n",
    "In order to accomplish this, we used `predict_proba` and chose the top two predicted classes for each crime. We used the model trained on the training set, and tested it on the test set to see how good of an accuracy we could get. We were hoping for an accuracy above 75% for a reliable and applicable tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of guesses that contained correct category: 74.2 %\n"
     ]
    }
   ],
   "source": [
    "# get list of categories \n",
    "caterogies = np.array(sorted(y_test.unique()))\n",
    "\n",
    "# use model to predict probabilities of each class\n",
    "predict_probas = model.predict_proba(X_test)\n",
    "\n",
    "# keep track of how many predicted pairs contained the correct category\n",
    "correct = 0\n",
    "\n",
    "# evaluate model\n",
    "for i in range(len(predict_probas)):\n",
    "    if list(y_test)[i] in list(caterogies[predict_probas[i].argsort()[-2:][::-1]]): correct += 1\n",
    "    else: pass\n",
    "\n",
    "# calculate percentage guessed right\n",
    "test_accuracy = correct / len(predict_probas)\n",
    "print('percent of guesses that contained correct category:',round(100*test_accuracy,1),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'police_min_dist'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[np.argmax(model.feature_importances_)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
