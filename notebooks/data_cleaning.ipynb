{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "Import the data and clean for EDA. Drop columns that don't relate to our analysis, drop rows with unusable data or that are not in our time frame (2015-2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read in Files__ from csv into pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_2019_full    = pd.read_csv('data/property-assessment-fy2019.csv')\n",
    "property_2018_full    = pd.read_csv('data/property-assessment-fy2018.csv')\n",
    "property_2017_full    = pd.read_csv('data/property-assessment-fy2017.csv')\n",
    "property_2016_full    = pd.read_csv('data/property-assessment-fy2016.csv')\n",
    "property_2015_full    = pd.read_csv('data/property-assessment-fy2015.csv')\n",
    "streetlights_full     = pd.read_csv('data/streetlight_locations.csv')\n",
    "crime_incidents_full  = pd.read_csv('data/crime_incident_reports.csv')\n",
    "weather_full          = pd.read_csv('data/weather_boston.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drop Columns__ after careful inspection of the data contained in each dataset, drop columns that will not help in our modeling. Columns were dropped if they had no effect on the outcome of interest (such as indeces or number of fireplaces in a property) or if the information in them was a duplicate (such as location if we were already given longitude and latitude).\n",
    "\n",
    "1. from `streetlamps` drop everything but `Long` and `Lat` \n",
    "2. from `property_assessment` we only care where the property is and what it's valued at so drop everything that doesn't relate; `AV_TOTAL` is nonzero for most entries, and is the easiest representative of a property's value\n",
    "3. from `crime_incidents` drop `Location` and the index, since the location information was duplicationg `Long` and `Lat` and the index was not useful for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop everything but lat and long\n",
    "streetlights = streetlights_full.drop(['the_geom','TYPE','OBJECTID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties columns to save  \n",
    "property_cols = ['ST_NUM','ST_NAME','ST_NAME_SUF','ZIPCODE','AV_TOTAL']\n",
    "\n",
    "# drop all columns not in list (keep _ at end of name to show not fully clean yet)\n",
    "property_2019_ = property_2019_full[property_2019_full.columns[property_2019_full.columns.isin(property_cols)]]\n",
    "property_2018_ = property_2018_full[property_2018_full.columns[property_2018_full.columns.isin(property_cols)]]\n",
    "property_2017_ = property_2017_full[property_2017_full.columns[property_2017_full.columns.isin(property_cols)]]\n",
    "property_2016_ = property_2016_full[property_2016_full.columns[property_2016_full.columns.isin(property_cols)]]\n",
    "property_2015_ = property_2015_full[property_2015_full.columns[property_2015_full.columns.isin(property_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crime columns to keep\n",
    "crime_col = ['OCCURRED_ON_DATE','UCR_PART','HOUR','SHOOTING','DAY_OF_WEEK','Lat','Long']\n",
    "\n",
    "# drop unwanted crime cols\n",
    "crime_incidents_ = crime_incidents_full[crime_incidents_full.columns[crime_incidents_full.columns.isin(crime_col)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather columns to keep\n",
    "weather_cols = ['DATE','PRCP','SNOW','TAVG']\n",
    "weather_boston = weather_full[weather_full.columns[weather_full.columns.isin(weather_cols)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drop Rows__ that would not be usable in the forseeable future. This includes rows that have no predictor data, or no response variable data, in the form of 'nan' or 'none' or in some cases zeros. Careful inspection of each dataset led us to drop the following:\n",
    "1. the `streetlights` dataset had no rows with immediately visible issues\n",
    "2. from `property_assessment` we dropped all rows that had 0 in all four of the price variables, no issues with location were immediately visible\n",
    "3. from `crime_incidents` we dropped if `Lat` and `Long` did not have usable values because it would be hard to get that information just from the street name and it is vital to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def property_droprows(df):\n",
    "    \n",
    "    # drop row if price is 0\n",
    "    df_new = df[df.AV_TOTAL > 0]\n",
    "    \n",
    "    # drop rows with no street number because then the lat long is very off\n",
    "    df_new = df_new[df_new['ST_NUM'].str.strip().astype(bool)]\n",
    "    \n",
    "    # get rid of pesky date number\n",
    "    df_new = df_new[df_new.ST_NUM != '5-Feb']\n",
    "    \n",
    "    return(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop property rows for all years\n",
    "property_2019 = property_droprows(property_2019_)\n",
    "property_2018 = property_droprows(property_2018_)\n",
    "property_2017 = property_droprows(property_2017_)\n",
    "property_2016 = property_droprows(property_2016_)\n",
    "property_2015 = property_droprows(property_2015_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with nan long and lat \n",
    "crime_incidents = crime_incidents_.dropna(subset=['Lat','Long'])\n",
    "\n",
    "# drop rows with 0 or -1 long and lat\n",
    "crime_incidents = crime_incidents[crime_incidents.Lat != 0]\n",
    "crime_incidents = crime_incidents[crime_incidents.Long != -1]\n",
    "\n",
    "# tidy up shooting catigory to be binary\n",
    "crime_incidents['SHOOTING'].fillna(0,inplace=True)\n",
    "crime_incidents['SHOOTING'].replace('Y',1,inplace=True)\n",
    "\n",
    "# drop any URC NaN because that's the response variable and theres only 109 of them\n",
    "crime_incidents = crime_incidents[~crime_incidents.UCR_PART.isna()]\n",
    "\n",
    "# drop URC that are Other, leaving only parts 1,2,3 and theres only 1,600 of them\n",
    "crime_incidents = crime_incidents[~crime_incidents.UCR_PART.isin(['Other'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all days with NaN temp\n",
    "nan_temps = list(weather_boston[weather_boston.TAVG.isna()].index)\n",
    "\n",
    "# for rows with NaN average temp, replace with previous day's temp\n",
    "for day in nan_temps:\n",
    "    weather_boston.at[day,'TAVG'] = weather_boston.loc[day-1].TAVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Export to CSV__ export cleaned data to csv in the folder data for cleaner use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_2019.to_csv('data/property_2019.csv')\n",
    "property_2018.to_csv('data/property_2018.csv')\n",
    "property_2017.to_csv('data/property_2017.csv')\n",
    "property_2016.to_csv('data/property_2016.csv')\n",
    "property_2015.to_csv('data/property_2015.csv')\n",
    "\n",
    "weather_boston.to_csv('data/weather_cleaned.csv')\n",
    "crime_incidents.to_csv('data/crime_incidents.csv')\n",
    "streetlights.to_csv('data/streetlights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
