{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "Import the data and clean for EDA. Drop columns that don't relate to our analysis, drop rows with unusable data or that are not in our time frame (2015-2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cs109default ### \n",
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from random import randint \n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "### cs109default ### \n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)  # You should see a 2.0.0 here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read in Files__ from csv into pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_2019_full    = pd.read_csv('data/property-assessment-fy2019.csv')\n",
    "property_2018_full    = pd.read_csv('data/property-assessment-fy2018.csv')\n",
    "property_2017_full    = pd.read_csv('data/property-assessment-fy2017.csv')\n",
    "property_2016_full    = pd.read_csv('data/property-assessment-fy2016.csv')\n",
    "property_2015_full    = pd.read_csv('data/property-assessment-fy2015.csv')\n",
    "streetlights_full     = pd.read_csv('data/streetlight_locations.csv')\n",
    "crime_incidents_full  = pd.read_csv('data/crime_incident_reports.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read in 311__ seperately because it takes longer so you don't have to run if not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#incident_reports_full = pd.read_csv('data/311.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drop Columns__ after careful inspection of the data contained in each dataset, drop columns that will not help in our modeling. Columns were dropped if they had no effect on the outcome of interest (such as indeces or number of fireplaces in a property) or if the information in them was a duplicate (such as location if we were already given longitude and latitude).\n",
    "\n",
    "1. from `streetlamps` drop everything but `Long` and `Lat`\n",
    "2. from `property_assessment` we only care where the property is and what it's valued at so drop everything that doesn't relate\n",
    "3. from `crime_incidents` drop `Location` and the index, since the location information was duplicationg `Long` and `Lat` and the index was not useful for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop everything but lat and long\n",
    "streetlights = streetlights_full.drop(['the_geom','TYPE','OBJECTID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to save for properties\n",
    "property_cols = ['ST_NUM','ST_NAME','ST_NAME_SUF','UNIT_NUM','ZIPCODE',\n",
    "                 'AV_LAND','AV_BLDG','AV_TOTAL','GROSS_TAX']\n",
    "\n",
    "# drop all columns not in list (keep _ at end of name to show not fully clean yet)\n",
    "property_2019_ = property_2019_full[property_2019_full.columns[property_2019_full.columns.isin(property_cols)]]\n",
    "property_2018_ = property_2018_full[property_2018_full.columns[property_2018_full.columns.isin(property_cols)]]\n",
    "property_2017_ = property_2017_full[property_2017_full.columns[property_2017_full.columns.isin(property_cols)]]\n",
    "property_2016_ = property_2016_full[property_2016_full.columns[property_2016_full.columns.isin(property_cols)]]\n",
    "property_2015_ = property_2015_full[property_2015_full.columns[property_2015_full.columns.isin(property_cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to drop for crime incidents\n",
    "#Offense Code is a numerical code of offense description (redundant data)\n",
    "crime_cols_drop = ['INCIDENT_NUMBER','UCR_PART','Location', 'OFFENSE_CODE', 'OCCURRED_ON_DATE']\n",
    "\n",
    "# drop columns and keep only descriptors of crime, date, and location\n",
    "crime_incidents_ = crime_incidents_full.drop(crime_cols_drop,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Shooting Column' into Integer Boolean\n",
    "\n",
    "crime_incidents_['SHOOTING'].fillna(0, inplace = True)\n",
    "crime_incidents_['SHOOTING'].astype(str).value_counts()\n",
    "#print(crime_incidents_['SHOOTING'].value_counts())\n",
    "\n",
    "crime_incidents_['SHOOTING'].replace(('Y'), ('1'), inplace=True)\n",
    "crime_incidents_['SHOOTING'] = crime_incidents_['SHOOTING'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Drop Rows__ that would not be usable in the forseeable future. This includes rows that have no predictor data, or no response variable data, in the form of 'nan' or 'none' or in some cases zeros. Careful inspection of each dataset led us to drop the following:\n",
    "1. the `streetlights` dataset had no rows with immediately visible issues\n",
    "2. from `property_assessment` we dropped all rows that had 0 in all four of the price variables, no issues with location were immediately visible\n",
    "3. from `crime_incidents` we dropped if `Lat` and `Long` did not have usable values because it would be hard to get that information just from the street name and it is vital to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row if all price values are 0\n",
    "def property_droprows(df):\n",
    "    df_new = df[(df.AV_LAND != 0)  | (df.AV_BLDG != 0) | (df.AV_TOTAL != 0) | (df.GROSS_TAX != 0)]\n",
    "    return(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop property rows for all years\n",
    "property_2019 = property_droprows(property_2019_)\n",
    "property_2018 = property_droprows(property_2018_)\n",
    "property_2017 = property_droprows(property_2017_)\n",
    "property_2016 = property_droprows(property_2016_)\n",
    "property_2015 = property_droprows(property_2015_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking Data with Streetlights\n",
    "\n",
    "### Deal with NA values in the crime_incidents report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deal with NA Values for LAT/LONG in crime reports\n",
    "import pandas as pd\n",
    "\n",
    "# drop rows with nan long and lat \n",
    "crime_incidents = crime_incidents_.dropna(subset=['Lat','Long'])\n",
    "\n",
    "crime_incidents_nonull = crime_incidents_.dropna(how='any',axis=0) \n",
    "crime_incidents_[crime_incidents_['SHOOTING'].isna()]['SHOOTING'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Associating Data\n",
    "\n",
    "Describe how you will associate the location data in Street Lights with the location data in the Crime Incident Reports Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = zip(streetlights.Lat.values, streetlights.Long.values)\n",
    "itemDict = [{'Lat': item[0], 'Long': item[1]} for item in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, asin, sqrt\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n",
    "    return 12742 * asin(sqrt(a))\n",
    "\n",
    "def closest(data, v):\n",
    "    min1 = min(data, key=lambda p: distance(v['Lat'], v['Long'], p['Lat'], p['Long']))\n",
    "    return distance(min1['Lat'], min1['Long'], v['Lat'], v['Long'])\n",
    "\n",
    "def closest_mod2(data, v):\n",
    "    return min(data, key=lambda p: distance(v[1]['Lat'], v[1]['Long'], p['Lat'], p['Long']))\n",
    "\n",
    "def closest_mod(data, a, b):\n",
    "    return min(data, key=lambda p: distance(a, b, p['Lat'], p['Long']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04921646179397781"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest(itemDict, crime_incidents_nonull.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime_incidents_nonull['Lat'].values[1]\n",
    "\n",
    "crime_incidents_nonull['streetlight_distance'] = 0.0\n",
    "#closest(itemDict, crime_incidents_nonull.iloc[1]).get('Lat')\n",
    "#crime_incidents_nonull.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(crime_incidents_nonull.shape[0]):\n",
    "    x.append(closest(itemDict, crime_incidents_nonull.iloc[i]))\n",
    "                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x2 = [closest_mod2(itemDict, item) for item in crime_incidents_nonull[['Lat', 'Long']].iterrows()]\n",
    "#x = [item for item in crime_incidents_nonull[['Lat', 'Long']].iterrows()]\n",
    "#a = [closest_mod2(itemDict, x[i]) for i in range(crime_incidents_nonull.shape[0])]\n",
    "\n",
    "crime_incidents_nonull['streetlight_distance'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Lat and Long List to six floating point characters\n",
    "from collections import Counter\n",
    "\n",
    "lat = streetlights['Lat'].values\n",
    "lat = [ '%.6f' % elem for elem in lat ]\n",
    "long = streetlights['Long'].values\n",
    "long = [ '%.6f' % elem for elem in long ]\n",
    "\n",
    "crime_incidents_nonull_streetlamps = crime_incidents.round(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN WITH STREET LAMP DATA\n",
    "\n",
    "crime_incidents_nonull_streetlamps['LatSame'] = crime_incidents_nonull_streetlamps['Lat'].isin(lat) \n",
    "crime_incidents_nonull_streetlamps['LongSame'] = crime_incidents_nonull_streetlamps['Long'].isin(long)\n",
    "crime_incidents_nonull_streetlamps_idx = crime_incidents_nonull_streetlamps.index[(crime_incidents_nonull_streetlamps['LatSame'] == True) & (crime_incidents_nonull_streetlamps['LongSame'] == True)].tolist()\n",
    "\n",
    "crime_incidents_['in_streetlight'] = crime_incidents_.index.isin(crime_incidents_nonull_streetlamps_idx)\n",
    "crime_incidents_['in_streetlight'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Analysis of How Many Crimes are Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(not_in_street['SHOOTING'].value_counts()) #(0.432061803 of crimes are shooting)\n",
    "notinstreet = not_in_street['SHOOTING'].value_counts()[1] * 100/ not_in_street['SHOOTING'].value_counts()[0]\n",
    "print(notinstreet)\n",
    "\n",
    "in_street['SHOOTING'].value_counts() #(0.389619784830 of crimes are shooting)\n",
    "instreet = in_street['SHOOTING'].value_counts()[1] * 100/ in_street['SHOOTING'].value_counts()[0]\n",
    "print(instreet)\n",
    "\n",
    "print(in_street['SHOOTING'].value_counts()[1]  + in_street['SHOOTING'].value_counts()[0])\n",
    "print(not_in_street['SHOOTING'].value_counts()[1]  + not_in_street['SHOOTING'].value_counts()[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
